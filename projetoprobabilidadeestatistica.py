# -*- coding: utf-8 -*-
"""ProjetoProbabilidadeEstatistica.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pj-B05u490-lBMpbSxMvlL101VRZP0JU

**COE241 - Estat√≠stica e Modelos Probabil√≠sticos**

COS868 - Probabilidade e Estat√≠stica

Segundo Semestre de 2025

Prof¬™: Rosa Maria Meri Le√£o

Projeto do Curso - Primeira Parte

**1. Objetivo**

O objetivo deste trabalho √© aplicar a teoria de Estat√≠stica, M√°xima Verossimilhan√ßa e Infer√™ncia Bayesiana a um conjunto de dados real. √â essencial que seja realizada uma an√°lise e interpreta√ß√£o dos resultados encontrados em todas as etapas.

O dataset a ser analisado cont√©m medi√ß√µes de par√¢metros de conex√µes da Internet.
As an√°lises incluem:

* Calcular estat√≠sticas descritivas e elaborar gr√°ficos explorat√≥rios.
* Ajustar modelos param√©tricos utilizando a M√°xima Verossimilhan√ßa (MLE).
* Realizar infer√™ncia bayesiana com priors conjugadas para obter as posteriors e
previs√µes.
* Comparar as estimativas MLE vs Bayes.

**2. Conjuntos de Dados**

####M-Lab NDT (Medi√ß√µes de desempenho de rede Internet)
Este dataset possui dados de desempenho de rede (throughput, RTT, perda de pacotes)
com acesso p√∫blico via BigQuery. Para este projeto, ser√° usado um subconjunto.
* O conjunto de dados ser√° fornecido no arquivo *ndt_tests_tratado.csv*.
* As vari√°veis incluem: **throughput** de download e upload (em bits por segundo), **RTT** de download e upload (em segundos) e **fra√ß√£o de perda de pacotes** (percentual).
* O dataset possui 13 clientes e 7 servidores. A primeira coluna cont√©m a data e a hora da coleta dos dados.
"""

# Commented out IPython magic to ensure Python compatibility.
# Importa√ß√£o de bibliotecas para utilizar de dataset

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from scipy.stats import pearsonr
# %matplotlib inline

# Importa√ß√£o do dataset

df = pd.read_csv('/content/ndt_tests_corrigido.csv')

pd.set_option('display.max_columns', None)
pd.set_option('display.width', 1000)

# Visualiza√ß√£o das primeiras linhas do dataset:

print(df.head(5))

# Informa√ß√µes gerais do dataset:

print(df.info())

# Algumas Estat√≠sticas descritivas do dataset:

print(df.describe())

"""**3. Tarefas do Projeto**

**3.1 An√°lise Explorat√≥ria de Dados (EDA)**


* Calcule as estat√≠sticas descritivas: m√©dia, mediana, vari√¢ncia, desvio padr√£o, e
quantis selecionados (por exemplo, 0,9, 0,99, etc.). Justifique a escolha dos
quantis mais relevantes para a an√°lise de desempenho de rede (por exemplo, observar a cauda da lat√™ncia).
* As estat√≠sticas devem ser calculadas para cada vari√°vel de interesse (throughput, RTT e fra√ß√£o de perda), para cada cliente e cada servidor. Elabore tabelas de
resumo e comente as diferen√ßas observadas entre os clientes e entre os servidores.

* Selecione dois clientes ou um cliente e um servidor que apresentem compor-
tamentos distintos ou interessantes para as an√°lises gr√°ficas e modelagem.

* Para os clientes e servidores selecionados, crie os gr√°ficos: histograma, boxplot, scatter plot (escolha um par de vari√°veis relevante). Analise e comente as distribui√ß√µes observadas.

* A partir dos gr√°ficos, defina um modelo param√©trico candidato (e.g., Normal,
Gamma, Binomial, etc.) para cada uma das cinco vari√°veis: throughput (up e
down), RTT (up e down) e perda.
"""

def contar_clientes(df):
    clientes_unicos = df['client'].unique()
    num_clientes = len(clientes_unicos)

    return clientes_unicos, num_clientes;

clientes_unicos, num_clientes = contar_clientes(df)
print(f"üì° N√∫mero total de clientes √∫nicos: {num_clientes}")

def contar_servidores(df):
    servidores_unicos = df['server'].unique()
    num_servidores = len(servidores_unicos)

    return servidores_unicos, num_servidores;

# Chamar a fun√ß√£o
servidores_unicos, num_servidores = contar_servidores(df)
print(f"üì° N√∫mero total de servidores √∫nicos: {num_servidores}")

"""Escolha de quantis:
* Cauda direita (valores altos) ‚Üí lat√™ncia ‚Üí indica problemas de atraso ou congestionamento.

* Cauda esquerda (valores baixos) ‚Üí throughput, pacotes, desempenho de download/upload ‚Üí indica usu√°rios com desempenho ruim ou falhas na rede.

Se o foco √© desempenho de rede, √© bom analisar quantis que permitam observar a cauda da lat√™ncia. Portanto 0.9 (90¬∫ percentil) mostra a lat√™ncia alta t√≠pica, ou seja, 90% das medi√ß√µes s√£o menores que esse valor.

Throughput (download/upload) ‚Üí o quantil 0.1 mostra os 10% de usu√°rios com menor desempenho, o que ajuda a identificar casos de gargalos na rede.

Pacotes recebidos ou transferidos ‚Üí quantil 0.1 (10% percentil) pode representar falhas ou perdas significativas mas tambem analisar 90% para importante para confiabilidade da rede
"""

#Para todos os clientes:
def calcular_estatisticas(df):
    df_num = df.select_dtypes(include='number')

    resultados = {}
    for col in df_num.columns:
        resultados[col] = {
            'mean': df[col].mean(),
            'median': df[col].median(),
            'var': df[col].var(),
            'std': df[col].std(),
            'q10': df[col].quantile(0.1),
            'q90': df[col].quantile(0.9)
        }

    tabela = pd.DataFrame(resultados).T

    # Arredonda para 2 casas decimais e desativa nota√ß√£o cient√≠fica
    tabela = tabela.applymap(lambda x: f"{x:.3e}")

    return tabela

tabela = calcular_estatisticas(df)
tabela

# Fun√ß√£o para calcular estat√≠sticas por grupo
def estatisticas_personalizadas(grupo):
    resultados = {}
    for metrica in metricas:
        resultados[f'{metrica}_mean'] = grupo[metrica].mean()
        resultados[f'{metrica}_median'] = grupo[metrica].median()
        resultados[f'{metrica}_var'] = grupo[metrica].var()
        resultados[f'{metrica}_std'] = grupo[metrica].std()
        for q in quantis:
            resultados[f'{metrica}_q{int(q*100)}'] = grupo[metrica].quantile(q)

    resultados = {k: f"{v:.3e}" for k, v in resultados.items()}

    return pd.Series(resultados)

estatisticas = ['mean', 'median', 'var', 'std'];

metricas = [
    'download_throughput_bps',
    #'upload_throughput_bps',
    #'rtt_download_sec',
    #'rtt_upload_sec',
    #'packet_loss_percent'
    ]

quantis = [ 0.1, 0.9]

# Estat√≠sticas por CLIENTE
estatisticas_cliente = df.groupby('client').apply(estatisticas_personalizadas).reset_index()
display(estatisticas_cliente)

# Estat√≠sticas por SERVIDOR
estatisticas_servidor = df.groupby('server').apply(estatisticas_personalizadas).reset_index()
display(estatisticas_servidor)

"""An√°lise *download_throughput_bps* :
1. Clientes
    * client08, client10
      * m√©dias abaixo do padr√£o geral
      * q10 baixos indicam casos de throughput cr√≠tico
      * menores variancias e desvio padr√£o, indica comportamento com pouca varia√ß√£o.

    * client01, client02, client09
      * m√©dias acima do padr√£o geral (considerando todos os clientes)
      * q90 semelhante ao padr√£o geral.
2. Servidores

    * server01
      * Maior performance, pois m√©dias acima do padr√£o geral.
    
    * server04
      * Menor performance, pois m√©dias abaixo do padr√£o geral.
"""

metricas = [
    #'download_throughput_bps',
    'upload_throughput_bps',
    #'rtt_download_sec',
    #'rtt_upload_sec',
    #'packet_loss_percent'
    ]
quantis = [ 0.1, 0.9]

# Estat√≠sticas por CLIENTE
estatisticas_cliente = df.groupby('client').apply(estatisticas_personalizadas).reset_index()
display(estatisticas_cliente)

# Estat√≠sticas por SERVIDOR
estatisticas_servidor = df.groupby('server').apply(estatisticas_personalizadas).reset_index()
display(estatisticas_servidor)

"""An√°lise *upload_throughput_bps* :
1. Clientes
    * client08, client10, client12
      * m√©dias abaixo do padr√£o geral, sendo a do client10 a pior de todas
      * q10 baixos indicam casos de throughput cr√≠tico
      * menores variancias e desvio padr√£o, indica comportamento com pouca varia√ß√£o.

    * client01, client02
      * m√©dias acima do padr√£o geral, sendo a do client01 a melhor
      * q10 indica que mesmo os piores testes de upload s√£o altos

Clientes de alta performance t√™m m√©dia e quantis altos, mas variancia e desvio padrao mais altos. Clientes de baixa performance possuem upload limitado, j√° que alguns possuem at√© mesmo o q90 √© baixo.

2. Servidores

    * server03
      * Maior performance, pois m√©dias acima do padr√£o geral e mediana consistente com a m√©dia.
    
    * server04 e 06
      * Menor performance, pois m√©dias abaixo do padr√£o geral, com medianas consistentes com a m√©dia, porem server04 ainda possui menor variancia indicando performance ruim com pouca variacao. Al√©m de q90 abaixo do padrao geral, mesmo para os 90% maiores dados de upload.

"""

quantis = [ 0.9]

metricas = [
    #'download_throughput_bps',
    #'upload_throughput_bps',
    'rtt_download_sec',
    #'rtt_upload_sec',
    #'packet_loss_percent'
    ]

# Estat√≠sticas por CLIENTE
estatisticas_cliente = df.groupby('client').apply(estatisticas_personalizadas).reset_index()
display(estatisticas_cliente)

# Estat√≠sticas por SERVIDOR
estatisticas_servidor = df.groupby('server').apply(estatisticas_personalizadas).reset_index()
display(estatisticas_servidor)

"""An√°lise *rtt_download_sec*:

1. Clientes

    * client11, client13
      * lat√™ncia m√©dia muito baixa, q90 baixo indicando que mesmo os piores casos de lat√™ncia s√£o baixos, clientes com desempenho pareciso sendo o client13 melhor.
      * baixa variancia e desvio, rede est√°vel.

    * client10, client12
      * Piores clientes pois possui maior valor m√©dio de latencia e maior q90, picos de latencia significativos (desvio padrao), comportamento inst√°vel.

2. Servidores

    * server01

      * Melhor servidor, pois possui menor q90, indicando que os 10% maiores valores de latencia sao aceitaveis.
      * Lat√™ncia baixa e std baixo, rede est√°vel.

    * server06

      * Pior servidor, maior m√©dia e maior q90, indicando que os 10% maiores valores de latencia sao muito altos.

      * Lat√™ncia alta nos picos e std alto, indicando instabilidade significativa.

Servidores de melhor performance apresentam RTT baixo e consistente, enquanto os de pior performance apresentam picos de lat√™ncia altos e vari√¢ncia elevada, destacando gargalos na rede.
"""

metricas = [
    #'download_throughput_bps',
    #'upload_throughput_bps',
    #'rtt_download_sec',
    'rtt_upload_sec',
    #'packet_loss_percent'
    ]


# Estat√≠sticas por CLIENTE
estatisticas_cliente = df.groupby('client').apply(estatisticas_personalizadas).reset_index()
display(estatisticas_cliente)

# Estat√≠sticas por SERVIDOR
estatisticas_servidor = df.groupby('server').apply(estatisticas_personalizadas).reset_index()
display(estatisticas_servidor)

"""An√°lise *rtt_upload_sec* :

1. Clientes

    * client11 e client13
      * Melhor cliente √© o 13, com menor medias de latencia na rede, e q90 baixos, indicando picos de latencia baixos, al√©m de baixa variancia.

    * client12
      * latencia m√©dia elevada, picos muito altos, especialmente se comparados com o melhor cliente, grande varia√ß√£o nos testes.

2. Servidores

    * server07
      * menor latencia m√©dia e consistente com mediana, e menor q90, indicando picos de latencia muito baixos, al√©m de rede estavel pois variancia e desvio sao menores.

    * server06
      * pior servidor, com maior latencia m√©dia, picos de latencia elevados (q90), e grande variacao nos dados.
"""

metricas = [
    #'download_throughput_bps',
    #'upload_throughput_bps',
    #'rtt_download_sec',
    #'rtt_upload_sec',
    'packet_loss_percent'
    ]


# Estat√≠sticas por CLIENTE
estatisticas_cliente = df.groupby('client').apply(estatisticas_personalizadas).reset_index()
display(estatisticas_cliente)

# Estat√≠sticas por SERVIDOR
estatisticas_servidor = df.groupby('server').apply(estatisticas_personalizadas).reset_index()
display(estatisticas_servidor)

"""An√°lise *packet_loss_percent* :

1. Clientes

      * client01, client12
        * menores perdas m√©dias, q90 baixo indicando poucos picos de perda de pacotes, baixa variacao, principalmente no cliente12.

      * client05, client08, client13
        * alta perda m√©dia de pacotes, grande variacao nos dados, sendo client08 com maior variancia e maior q90, indicando picos grandes de perda de pacote, o que afeta a confiabilidade da comunicacao. enquanto client05 possui maior media.


2. Servidores

      * server07 e server02
        * melhores servidores, pois possuem menor media, picos baixos representados pelo q90, e variancia moderada, sendo o melhor o server07.


      * server01 e server05
        * piores valores, com maior m√©dia, picos altos de perda e grande variabilidade nos dados. sendo o server05 o pior em termos de media, q90 e variancia.

Escolha de clientes com comportamento distinto:
  * client02, aprensenta um throughput bom com valores acima da media, apresenta as valores abaixo da m√©dia para latencia e √© um cliente com baixa perda de pacotes.
  * client12, aprensenta um throughput nao t√£o bom com valores abaixo da media, apresenta as piores latencia no geral, mas tamb√©m √© um cliente com baixa perda de pacotes.

Plotando graficos para os clientes escolhidos:

1. Throughput download
"""

variaveis = {
    "download_throughput_bps": "Throughput Download (bps)",
    "upload_throughput_bps": "Throughput Upload (bps)",
    "rtt_download_sec": "RTT Download (s)",
    "rtt_upload_sec": "RTT Upload (s)",
    "packet_loss_percent": "Perda de Pacotes (%)"
}

clientes = df[df["client"].isin(["client02", "client12"])]

fig, axes = plt.subplots(1, 3, figsize=(14, 3))

# Histograma - Download
sns.histplot(data=clientes, x="download_throughput_bps", hue="client", kde=True, bins=40, alpha=0.5, ax=axes[0])
axes[0].set_title("Histograma - Throughput Download")
axes[0].set_xlabel("Throughput (bps)")
axes[0].set_ylabel("Frequ√™ncia")

# Boxplot - Download
sns.boxplot(data=clientes, x="client", y="download_throughput_bps", ax=axes[1])
axes[1].set_title("Boxplot - Throughput Download")
axes[1].set_xlabel("Cliente")
axes[1].set_ylabel("Throughput (bps)")

# Scatter plot - Download vs RTT Download
sns.scatterplot(data=clientes, x="rtt_download_sec", y="download_throughput_bps", hue="client", style="client", s=70, ax=axes[2])
axes[2].set_title("Scatter - Throughput Download vs RTT Download")
axes[2].set_xlabel("RTT Download (s)")
axes[2].set_ylabel("Throughput (bps)")

plt.tight_layout()
plt.show()

"""Pelo histograma √© possivel ver que os dados sao mais distribuidos em valores altos, contudo o cliente possui um pico em valores baixos, o que √© era esperado j√° que foi analizado como um candidato que tinha throughput ruim. J√° o cliente 02, tambem possui um pico em valores baixos, mas com menor frequencia e possui valores mais altos com mais frequencia. Pela analise do grafico √© possivel observar uma distribui√ß√£o bimodal, portanto um modelo composto por duas gammas pode se ajustar bem a essa variavel.

2. Throughput upload
"""

fig, axes = plt.subplots(1, 3, figsize=(14, 3))

# Histograma - Upload
sns.histplot(data=clientes, x="upload_throughput_bps", hue="client", kde=True, bins=40, alpha=0.5, ax=axes[0])
axes[0].set_title("Histograma - Throughput Upload")
axes[0].set_xlabel("Throughput (bps)")
axes[0].set_ylabel("Frequ√™ncia")

# Boxplot - Upload
sns.boxplot(data=clientes, x="client", y="upload_throughput_bps", ax=axes[1])
axes[1].set_title("Boxplot - Throughput Upload")
axes[1].set_xlabel("Cliente")
axes[1].set_ylabel("Throughput (bps)")

# Scatter plot - Upload vs RTT Upload
sns.scatterplot(data=clientes, x="rtt_upload_sec", y="upload_throughput_bps", hue="client", style="client", s=70, ax=axes[2])
axes[2].set_title("Scatter - Throughput Upload vs RTT Upload")
axes[2].set_xlabel("RTT Upload (s)")
axes[2].set_ylabel("Throughput (bps)")

plt.tight_layout()
plt.show()

"""Pelo histograma √© possivel ver que os dados sao distribuidos mais uniformemente para upload. O cliente 12 tem desempenho baixo a todo momento, com frequencia alta em valores baixos de throughput. enquanto cliente 2 possui dois picos, mas maior concentracao em valores altos. Alguns outliers aparecem no grafico de boxplot para o pico com valores inferiores. Dessa forma, um modelo composto por uma variavel gamma ou normal pode se adequar bem nesse caso. Seguindo a sugestao da da se√ß√£o 4.3, vai ser adotado a distribui√ß√£o gamma para ambos throughputs, download e upload.

3. RTT download
"""

fig, axes = plt.subplots(1, 3, figsize=(14, 3))

# Histograma - RTT Download
sns.histplot(data=clientes, x="rtt_download_sec", hue="client", kde=True, bins=40, alpha=0.5, ax=axes[0])
axes[0].set_title("Histograma - RTT Download")
axes[0].set_xlabel("RTT Download (s)")
axes[0].set_ylabel("Frequ√™ncia")

# Boxplot - RTT Download
sns.boxplot(data=clientes, x="client", y="rtt_download_sec", ax=axes[1])
axes[1].set_title("Boxplot - RTT Download")
axes[1].set_xlabel("Cliente")
axes[1].set_ylabel("RTT Download (s)")

# Scatter plot - RTT Download vs Throughput Download
sns.scatterplot(data=clientes, x="rtt_download_sec", y="download_throughput_bps", hue="client", style="client", s=70, ax=axes[2])
axes[2].set_title("Scatter - RTT Download vs Throughput Download")
axes[2].set_xlabel("RTT Download (s)")
axes[2].set_ylabel("Throughput Download (bps)")

plt.tight_layout()
plt.show()

"""Tamb√©m apresenta distribuicao bimodal, mas o cliente 02 com valores baixos de latencia enquanto o cliente 12 tem valores altos de latencia com maior frequencia, mas tambem opera em valores baixos. essa situacao pode indicar diferentes condicoes na rede, j√° que ambos os clientes tem essa caracteristica bimodal na distribuicao. Tamb√©m √© possivel observar uma presenca de cauda longa a direita, o que pode indicar possivelmente um modelo composto por gamma j√° que sao sempre positivas e tendencia de valores com menor frequencia a direita, portando como existe bimodalidade, possivelmente uma gamma ou normal ou uma composicao de duas do mesmo tipo faz sentido.

Portanto, como sugerido na se√ß√£o 4.1, vai ser adotado a distribui√ß√£o normal para ambos RTT download e upload.

4. RTT upload
"""

fig, axes = plt.subplots(1, 3, figsize=(14, 3))

# Histograma - RTT Upload
sns.histplot(data=clientes, x="rtt_upload_sec", hue="client", kde=True, bins=40, alpha=0.5, ax=axes[0])
axes[0].set_title("Histograma - RTT Upload")
axes[0].set_xlabel("RTT Upload (s)")
axes[0].set_ylabel("Frequ√™ncia")

# Boxplot - RTT Upload
sns.boxplot(data=clientes, x="client", y="rtt_upload_sec", ax=axes[1])
axes[1].set_title("Boxplot - RTT Upload")
axes[1].set_xlabel("Cliente")
axes[1].set_ylabel("RTT Upload (s)")

# Scatter plot - RTT Upload vs Throughput Upload
sns.scatterplot(data=clientes, x="rtt_upload_sec", y="upload_throughput_bps", hue="client", style="client", s=70, ax=axes[2])
axes[2].set_title("Scatter - RTT Upload vs Throughput Upload")
axes[2].set_xlabel("RTT Upload (s)")
axes[2].set_ylabel("Throughput Upload (bps)")

plt.tight_layout()
plt.show()

"""Mesmo caso observado em latencia de download mas aqui o pico com maior latencia possui ainda menor frequencia, indicando que um modelo utilizando gamma ou normal √© uma escolha razoavel. Pelo grafico de blocpot tamb√©m podemos observar que faz sentido j√° que existem muitos outliers fora dos quartis, e que os valores sao concentrados em latencia baixa, principalmente para o cliente 2.

5. loss packages
"""

fig, axes = plt.subplots(1, 3, figsize=(14, 3))

# Histograma - Packet Loss
sns.histplot(data=clientes, x="packet_loss_percent", hue="client", kde=True, bins=40, alpha=0.5, ax=axes[0])
axes[0].set_title("Histograma - Packet Loss")
axes[0].set_xlabel("Perda de Pacotes (%)")
axes[0].set_ylabel("Frequ√™ncia")

# Boxplot - Packet Loss
sns.boxplot(data=clientes, x="client", y="packet_loss_percent", ax=axes[1])
axes[1].set_title("Boxplot - Packet Loss")
axes[1].set_xlabel("Cliente")
axes[1].set_ylabel("Perda de Pacotes (%)")

# Scatter plot - Packet Loss vs Throughput Download
sns.scatterplot(data=clientes, x="packet_loss_percent", y="download_throughput_bps", hue="client", style="client", s=70, ax=axes[2])
axes[2].set_title("Scatter - Packet Loss vs Throughput Download")
axes[2].set_xlabel("Perda de Pacotes (%)")
axes[2].set_ylabel("Throughput Download (bps)")

plt.tight_layout()
plt.show()

"""Para porcentagem de perda de pacotes, uma distribuicao gamma poderia se aplicar desde que √© visivel a cauda longa a direita, com concentracao alta em valores baixos de perda. Contudo o dom√≠nio da gamma √© de (0, infinito), e como essa variavel √© representada em porcentagem, ou seja, contem apenas valores entre 0 e 1, um modelo utilizando beta pode ser uma boa alternativa nesse caso. Portando, assim como sugerido na se√ß√£o 4.2, o modelo a ser adotado √© Beta-Binomial.

**3.2 M√°xima Verossimilhan√ßa (MLE)**

Utilize o m√©todo da M√°xima Verossimilhan√ßa (MLE) para estimar os par√¢metros dos
modelos definidos na se√ß√£o anterior.

* Defina o Estimador de M√°xima Verossimilhan√ßa $\hat{\theta}_{MLE}$ para cada modelo. Apresente os valores num√©ricos.

* Avalia√ß√£o do Ajuste: Crie gr√°ficos comparativos para diagnosticar o ajuste do
modelo:
1. Histograma dos dados reais em conjunto com a fun√ß√£o densidade/massa de
probabilidade do modelo ajustado usando o $\hat{\theta}_{MLE}$.
2. QQ plot dos dados reais versus quantis te√≥ricos do modelo ajustado.

**Throughput download e upload (Distribui√ß√£o Gamma):**

1. Likelihood (Verossimilhan√ßa): As observa√ß√µes de throughput $Y = (y_1, \ldots, y_n)$ s√£o modeladas por uma distribui√ß√£o Gamma com *shape* $k > 0$ (fixo e conhecido) e *rate* $\beta > 0$ (desconhecido).

$$
y_i \mid \beta \sim \text{Gamma}(k, \beta).
\tag{1}
$$

A fun√ß√£o densidade de probabilidade (PDF) √©:

$$
f(y \mid k, \beta) = \frac{\beta^k}{\Gamma(k)} y^{k-1} e^{-\beta y},
\quad y > 0.
\tag{2}
$$

2. Prior (A Priori): Escolhemos a *prior* conjugada para o par√¢metro de taxa $\beta$, que √© tamb√©m uma distribui√ß√£o Gamma com hiperpar√¢metros $a_0$ e $b_0$.

$$
\beta \sim \text{Gamma}(a_0, b_0).
\tag{3}
$$

Pr√≥ximo passo √© encontrar os parametros para cada Throughput download e upload (considerando todos os clientes, e tambem o cliente 02 e 12).

Obs: Como a variavel gama considera apenas valores positivos, o que faz sentido considerando a variavel de throuput, ser√° realizada uma limpeza em dados negativos nessa etapa, de modo que caso existam valores negativos devido a erros de medicao ou qualquer outro motivo, nao seja retornado nenhum tipo de erro na modelagem.
"""

from scipy.stats import norm, gamma, binom, probplot
from scipy.special import digamma, loggamma, gamma as gamma_func
from scipy.optimize import minimize # Para o MLE manual, se necess√°rio

df_02 = df[df['client'] == 'client02'].copy()
df_12 = df[df['client'] == 'client12'].copy()

# Throughput Download utilizando funcao gamma que possui melhor aproximacao de parametros do que caso feito por momento.

th_down = df['download_throughput_bps']
th_down = th_down[th_down > 0]
k_mle_th_down, loc_mle_th_down, scale_mle_th_down = gamma.fit(th_down, floc=0)
beta_mle_th_down = 1 / scale_mle_th_down

th_down_02 = df_02['download_throughput_bps']
th_down_02 = th_down_02[th_down_02 > 0]
k_mle_th_down_02, loc_mle_th_down_02, scale_mle_th_down_02 = gamma.fit(th_down_02, floc=0)
beta_mle_th_down_02 = 1 / scale_mle_th_down_02

th_down_12 = df_12['download_throughput_bps']
th_down_12 = th_down_12[th_down_12 > 0]
k_mle_th_down_12, loc_mle_th_down_12, scale_mle_th_down_12 = gamma.fit(th_down_12, floc=0)
beta_mle_th_down_12 = 1 / scale_mle_th_down_12

#print(f"Throughput Download: Gamma(k={k_mle_th_down:.4f}, beta={beta_mle_th_down:.4e})")
#print(f"Throughput Download: Gamma(k={k_mle_th_down_02:.4f}, beta={beta_mle_th_down_02:.4e}) (client02)")
#print(f"Throughput Download: Gamma(k={k_mle_th_down_12:.4f}, beta={beta_mle_th_down_12:.4e}) (client12)\n")

th_up = df['upload_throughput_bps']
th_up = th_up[th_up > 0]
mle_th_up_k, _, mle_th_up_scale = gamma.fit(th_up, floc=0)
mle_th_up_beta = 1 / mle_th_up_scale

th_up_02 = df_02['upload_throughput_bps']
th_up_02 = th_up_02[th_up_02 > 0]
mle_th_up_k_02, _, mle_th_up_scale_02 = gamma.fit(th_up_02, floc=0)
mle_th_up_beta_02 = 1 / mle_th_up_scale_02

th_up_12 = df_12['upload_throughput_bps']
th_up_12 = th_up_12[th_up_12 > 0]
mle_th_up_k_12, _, mle_th_up_scale_12 = gamma.fit(th_up_12, floc=0)
mle_th_up_beta_12 = 1 / mle_th_up_scale_12

#print(f"Throughput Upload: Gamma(k={mle_th_up_k:.4f}, beta={mle_th_up_beta:.4e})")
#print(f"Throughput Upload: Gamma(k={mle_th_up_k_02:.4f}, beta={mle_th_up_beta_02:.4e}) (client02)")
#print(f"Throughput Upload: Gamma(k={mle_th_up_k_12:.4f}, beta={mle_th_up_beta_12:.4e})(client12)")

print(f"Throughput Download: Gamma(k, beta)\n")
print(f"client      k         beta")
print(f"all       {k_mle_th_down:.4f}     {beta_mle_th_down:.4e} ")
print(f"02        {k_mle_th_down_02:.4f}     {beta_mle_th_down_02:.4e}")
print(f"12        {k_mle_th_down_12:.4f}     {beta_mle_th_down_12:.4e} ")

print(f"Throughput Upload: Gamma(k, beta)\n")
print(f"client      k         beta")
print(f"all       {mle_th_up_k:.4f}     {mle_th_up_beta:.4e} ")
print(f"02        {mle_th_up_k_02:.4f}     {mle_th_up_beta_02:.4e}")
print(f"12        {mle_th_up_k_12:.4f}     {mle_th_up_beta_12:.4e} ")

"""**RTT download e upload (Distribui√ß√£o Normal):**

1. Likelihood (Verossimilhan√ßa): A distribui√ß√£o dos dados, condicionada √† m√©dia $\mu$, √© Normal com vari√¢ncia $\sigma^2$ conhecida.

$$
r_i \mid \mu \sim \mathcal{N}(\mu, \sigma^2).
\tag{4}
$$

2. Prior (A Priori): A distribui√ß√£o a priori para o par√¢metro desconhecido Œº √©
tamb√©m Normal, caracterizada pela m√©dia $\mu_0$ e vari√¢ncia $\tau_0^2$

$$
\mu \sim \mathcal{N}(\mu_0, \tau_0^2).
\tag{5}
$$

Primeiro passo √© encontrar os parametros para cada RTT download e upload (considerando todos os clientes).



"""

from scipy.stats import norm, gamma, binom, probplot
from scipy.special import digamma, loggamma, gamma as gamma_func
from scipy.optimize import minimize # Para o MLE manual, se necess√°rio

# RTT Download
rtt_down = df['rtt_download_sec']
mle_rtt_down_media, mle_rtt_down_desvio = norm.fit(rtt_down)
mle_rtt_down_variancia = mle_rtt_down_desvio**2

rtt_down_02 = df_02['rtt_download_sec']
mle_rtt_down_media_02, mle_rtt_down_desvio_02 = norm.fit(rtt_down_02)
mle_rtt_down_variancia_02 = mle_rtt_down_desvio_02**2

rtt_down_12 = df_12['rtt_download_sec']
mle_rtt_down_media_12, mle_rtt_down_desvio_12 = norm.fit(rtt_down_12)
mle_rtt_down_variancia_12 = mle_rtt_down_desvio_12**2

#print(f"RTT Download: N({mle_rtt_down_media:.6f}, {mle_rtt_down_variancia:.6f})")
#print(f"RTT Download: N({mle_rtt_down_media_02:.6f}, {mle_rtt_down_variancia_02:.6f}) (client02)")
#print(f"RTT Download: N({mle_rtt_down_media_12:.6f}, {mle_rtt_down_variancia_12:.6f}) (client12)\n")

# RTT Upload
rtt_up = df['rtt_upload_sec']
mle_rtt_up_media, mle_rtt_up_desvio = norm.fit(rtt_up)
mle_rtt_up_variancia = mle_rtt_up_desvio**2

rtt_up_02 = df_02['rtt_upload_sec']
mle_rtt_up_media_02, mle_rtt_up_desvio_02 = norm.fit(rtt_up_02)
mle_rtt_up_variancia_02 = mle_rtt_up_desvio_02**2

rtt_up_12 = df_12['rtt_upload_sec']
mle_rtt_up_media_12, mle_rtt_up_desvio_12 = norm.fit(rtt_up_12)
mle_rtt_up_variancia_12 = mle_rtt_up_desvio_12**2

#print(f"RTT Upload: N({mle_rtt_up_media:.6f}, {mle_rtt_up_variancia:.6f})")
#print(f"RTT Upload: N({mle_rtt_up_media_02:.6f}, {mle_rtt_up_variancia_02:.6f}) (client02)")
#print(f"RTT Upload: N({mle_rtt_up_media_12:.6f}, {mle_rtt_up_variancia_12:.6f}) (client12)")

print(f"RTT Download: N(mu, sigma^2)\n")
print(f"client      mu        sigma^2")
print(f"all      {mle_rtt_down_media:.6f}    {mle_rtt_down_variancia:.6f} ")
print(f"02       {mle_rtt_down_media_02:.6f}    {mle_rtt_down_variancia_02:.6f} ")
print(f"12       {mle_rtt_down_media_12:.6f}    {mle_rtt_down_variancia_12:.6f} ")

print(f"RTT Upload: N(mu, sigma^2)\n")
print(f"client      mu        sigma^2")
print(f"all      {mle_rtt_up_media:.6f}    {mle_rtt_up_variancia:.6f} ")
print(f"02       {mle_rtt_up_media_02:.6f}    {mle_rtt_up_variancia_02:.6f} ")
print(f"12       {mle_rtt_up_media_12:.6f}    {mle_rtt_up_variancia_12:.6f} ")

"""**Packege loss (Beta‚ÄìBinomial):**

A fra√ß√£o de perda de pacotes ($p$) em redes de comunica√ß√£o √© uma propor√ß√£o que se encontra no intervalo $[0, 1]$. Esta caracter√≠stica torna o modelo Binomial uma escolha natural para a likelihood, com a distribui√ß√£o Beta servindo como a prior conjugada. O par Beta‚ÄìBinomial √© ideal para infer√™ncia Bayesiana sobre propor√ß√µes.

O modelo √© definido pela likelihood Binomial e pela prior Beta para a probabilidade de perda.

1. Likelihood (Verossimilhan√ßa): Considere $n_t$ pacotes enviados e $x_t$ pacotes perdidos no per√≠odo $t$. A contagem de perdas √© modelada por uma distribui√ß√£o Binomial, onde $p$ √© a probabilidade de perda em uma transmiss√£o:

$$
X_t \mid p \sim \text{Binomial}(n_t, p).
\tag{6}
$$

Obs: Como o dataset fornece a fra√ß√£o de perda (percentual), e o n√∫mero
real de pacotes ($n_t$) transmitidos em um teste NDT varia com o throughput e a dura√ß√£o, voc√™ deve assumir um n√∫mero fixo de pacotes transmitidos ($n_t$)
para converter a fra√ß√£o em contagem ($X_t$), permitindo o uso do modelo Binomial. Sugest√£o de Valor a ser Fixado: Para simplificar a an√°lise, sugere-se assumir um n√∫mero fixo de pacotes por observa√ß√£o, como, por exemplo, $n_t$ = 1000. O valor de $n_t$ (ou $n_{tot}$, o agregado) deve ser apresentado na se√ß√£o de Infer√™ncia Bayesiana.

2. Prior (A Priori): A distribui√ß√£o a priori para a probabilidade de perda $p \in [0,1]$  √© a distribui√ß√£o Beta, caracterizada pelos hiperpar√¢metros $a_0$ e $b_0$.

$$p \sim \text{Beta}(a_0, b_0).
\tag{8}$$

Primeiro passo √© encontrar os parametros para essa variavel (considerando todos os clientes).



"""

# √â sugerido fixar um n√∫mero de pacotes (nt) para converter a fra√ß√£o em contagem Xt .
nt_pacotes = 1000
# A coluna 'packet_loss_percent' √© um percentual, deve ser dividida por 100 para obter a fra√ß√£o.
df['perdas_contagem'] = (df['packet_loss_percent'] / 100) * nt_pacotes

df_02['perdas_contagem'] = (df_02['packet_loss_percent'] / 100) * nt_pacotes
df_12['perdas_contagem'] = (df_12['packet_loss_percent'] / 100) * nt_pacotes

x_tot = df['perdas_contagem'].sum()
n_tot = len(df) * nt_pacotes
mle_loss_p = x_tot / n_tot

x_tot_02 = df_02['perdas_contagem'].sum()
n_tot_02 = len(df_02) * nt_pacotes
mle_loss_p_02 = x_tot_02 / n_tot_02

x_tot_12 = df_12['perdas_contagem'].sum()
n_tot_12 = len(df_12) * nt_pacotes
mle_loss_p_12 = x_tot_12 / n_tot_12

#print(f"Package loss: Binomial(n_t={nt_pacotes}, p={mle_loss_p:.6f})")
#print(f"Package loss: Binomial(n_t={nt_pacotes}, p={mle_loss_p_02:.6f})")
#print(f"Package loss: Binomial(n_t={nt_pacotes}, p={mle_loss_p_12:.6f})")

print(f"Package loss: Binomial(n_t, p)\n")
print(f"client      n_t        p")
print(f"all        {nt_pacotes}     {mle_loss_p:.6f}")
print(f"02         {nt_pacotes}     {mle_loss_p_02:.6f}")
print(f"12         {nt_pacotes}     {mle_loss_p_02:.6f}")

"""Crie gr√°ficos comparativos para diagnosticar o ajuste do
modelo:
1. Histograma dos dados reais em conjunto com a fun√ß√£o densidade/massa de
probabilidade do modelo ajustado usando o $\hat{\theta}_{MLE}$.
2. QQ plot dos dados reais versus quantis te√≥ricos do modelo ajustado.
"""

def plot_mle_comparative_diagnostics(data_dict, distribution_name, param_keys, title):
    """
    Cria e exibe o Histograma vs. PDF/PMF (Subplot 1) e o QQ Plot ou Histograma com Zoom (Subplot 2).
    Ajustado para barras mais finas (mais bins ou visualiza√ß√£o discreta).
    """
    plt.style.use('seaborn-v0_8-whitegrid')
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))

    COLORS = {'client02': 'blue', 'client12': 'red'}

    # ---------------------------------------------------------------------
    # Subplot 1: Histograma vs. PDF/PMF (Geral)
    # ---------------------------------------------------------------------

    if distribution_name == 'Binomial':
        nt = 1000
        zoom_limit = 35

        # --- L√≥gica de Plotagem Comum para PMF/Histogramas (Binomial) ---
        def plot_binomial(ax, data_dict, nt, limit=None):
            for client, values in data_dict.items():
                data = values['data']
                p_mle = values['params'][0]
                color = COLORS[client]

                # 1. Histograma dos dados reais: Bins por inteiro, barras bem definidas.
                bins = np.arange(0, nt + 2) - 0.5
                if limit is not None:
                    bins = np.arange(0, limit + 2) - 0.5

                # Usando sns.histplot com ajuste de visualiza√ß√£o para barras mais n√≠tidas
                sns.histplot(data, bins=bins, stat="density", alpha=0.5, color=color,
                             ax=ax, label=f'{client} Reais (p={p_mle:.4f})',
                             discrete=True, edgecolor='black', linewidth=0.5)

                # 2. PMF do modelo ajustado
                k = np.arange(0, nt + 1)
                pmf_values = binom.pmf(k, nt, p_mle)

                k_plot = k
                pmf_plot = pmf_values
                if limit is not None:
                    k_plot = k[k <= limit]
                    pmf_plot = pmf_values[k <= limit]

                ax.plot(k_plot, pmf_plot, marker='o', linestyle='--', color=color, markersize=3,
                             label=f'{client} Modelo PMF')

            ax.set_xlabel('Contagem de Perdas (x)')
            ax.set_ylabel('Probabilidade / Frequ√™ncia Normalizada')
            ax.legend()

        # Plot Subplot 1: Histograma Completo
        plot_binomial(axes[0], data_dict, nt)
        axes[0].set_title(f'1. {title}: Histograma vs. Binomial PMF (Completo)')

        # Plot Subplot 2: Histograma com Zoom (0-50)
        plot_binomial(axes[1], data_dict, nt, limit=zoom_limit)
        axes[1].set_xlim(-1, zoom_limit + 1)
        axes[1].set_title(f'2. {title}: Histograma vs. Binomial PMF (Zoom 0-{zoom_limit})')


    else: # Distribui√ß√µes Cont√≠nuas (Gamma e Normal)
        all_data = pd.concat([values['data'] for values in data_dict.values()])
        xmin, xmax = all_data.min(), all_data.max()
        x = np.linspace(xmin, xmax, 1000)

        # AUMENTANDO O N√öMERO DE BINS PARA 75
        N_BINS = 75

        # ---------------------------------------------------------------------
        # Subplot 1: Histograma vs. PDF
        # ---------------------------------------------------------------------
        for client, values in data_dict.items():
            data = values['data']
            params = values['params']
            color = COLORS[client]

            # USANDO N_BINS = 50 para barras mais finas
            sns.histplot(data, bins=N_BINS, kde=False, stat="density", alpha=0.4, color=color,
                         ax=axes[0], label=f'{client} Dados Reais')

            if distribution_name == 'Normal':
                mu, sigma_sq = params
                std = np.sqrt(sigma_sq)
                p = norm.pdf(x, mu, std)
                axes[0].plot(x, p, color=color, linestyle='-', linewidth=2,
                             label=f'{client} Normal(Œº={mu:.4f})')

            elif distribution_name == 'Gamma':
                k, beta = params
                scale = 1/beta
                p = gamma.pdf(x, k, loc=0, scale=scale)
                axes[0].plot(x, p, color=color, linestyle='-', linewidth=2,
                             label=f'{client} Gamma(k={k:.4f}, Œ≤={beta:.2e})')

        axes[0].set_xlabel(title)
        axes[0].set_ylabel('Densidade')
        axes[0].set_title(f'1. {title}: Histograma vs. {distribution_name} PDF/PMF (Comparativo)')
        axes[0].legend()

        # ---------------------------------------------------------------------
        # Subplot 2: QQ Plot
        # ---------------------------------------------------------------------
        for client, values in data_dict.items():
            data = values['data']
            params = values['params']
            color = COLORS[client]

            if distribution_name == 'Normal':
                mu, sigma_sq = params
                std = np.sqrt(sigma_sq)
                dist = norm
                sparams = (mu, std)
            elif distribution_name == 'Gamma':
                k, beta = params
                scale = 1/beta
                dist = gamma
                sparams = (k, 0, scale)

            (osm, osr), (slope, intercept, r) = probplot(data, dist=dist, sparams=sparams, plot=None)

            axes[1].plot(osm, osr, marker='o', linestyle='', color=color, alpha=0.6,
                         label=f'{client} Dados Reais')

            axes[1].plot(osm, slope * osm + intercept, color=color, linestyle='--', linewidth=1.5,
                         label=f'{client} Linha MLE')

        axes[1].set_xlabel('Quantis Te√≥ricos do Modelo Ajustado')
        axes[1].set_ylabel('Quantis Amostrais (Dados Reais)')
        axes[1].set_title(f'2. QQ Plot (Dados vs. Modelo Ajustado)\n({title})')
        axes[1].legend()

    plt.tight_layout()
    plt.show()

# =========================================================================
# 2. CHAMADA DA FUN√á√ÉO (Executar√° a l√≥gica com barras mais finas)
# =========================================================================

# 1. Throughput Download (Gamma)
th_down_data_dict = {
    'client02': {
        'data': df_02['download_throughput_bps'].dropna()[df_02['download_throughput_bps'].dropna() > 0],
        'params': (globals()['k_mle_th_down_02'], globals()['beta_mle_th_down_02'])
    },
    'client12': {
        'data': df_12['download_throughput_bps'].dropna()[df_12['download_throughput_bps'].dropna() > 0],
        'params': (globals()['k_mle_th_down_12'], globals()['beta_mle_th_down_12'])
    }
}
plot_mle_comparative_diagnostics(th_down_data_dict, 'Gamma', ('k', 'beta'), "Throughput Download (bps)")

# 2. Throughput Upload (Gamma)
th_up_data_dict = {
    'client02': {
        'data': df_02['upload_throughput_bps'].dropna()[df_02['upload_throughput_bps'].dropna() > 0],
        'params': (globals()['mle_th_up_k_02'], globals()['mle_th_up_beta_02'])
    },
    'client12': {
        'data': df_12['upload_throughput_bps'].dropna()[df_12['upload_throughput_bps'].dropna() > 0],
        'params': (globals()['mle_th_up_k_12'], globals()['mle_th_up_beta_12'])
    }
}
plot_mle_comparative_diagnostics(th_up_data_dict, 'Gamma', ('k', 'beta'), "Throughput Upload (bps)")

# 3. RTT Download (Normal)
rtt_down_data_dict = {
    'client02': {
        'data': df_02['rtt_download_sec'].dropna(),
        'params': (globals()['mle_rtt_down_media_02'], globals()['mle_rtt_down_variancia_02'])
    },
    'client12': {
        'data': df_12['rtt_download_sec'].dropna(),
        'params': (globals()['mle_rtt_down_media_12'], globals()['mle_rtt_down_variancia_12'])
    }
}
plot_mle_comparative_diagnostics(rtt_down_data_dict, 'Normal', ('mu', 'var'), "RTT Download (segundos)")

# 4. RTT Upload (Normal)
rtt_up_data_dict = {
    'client02': {
        'data': df_02['rtt_upload_sec'].dropna(),
        'params': (globals()['mle_rtt_up_media_02'], globals()['mle_rtt_up_variancia_02'])
    },
    'client12': {
        'data': df_12['rtt_upload_sec'].dropna(),
        'params': (globals()['mle_rtt_up_media_12'], globals()['mle_rtt_up_variancia_12'])
    }
}
plot_mle_comparative_diagnostics(rtt_up_data_dict, 'Normal', ('mu', 'var'), "RTT Upload (segundos)")

# --- CHAMADA PARA PACKAGE LOSS (AGORA COM HISTOGRAMA + ZOOM) ---

# 5. Package Loss (Binomial)
loss_data_dict = {
    'client02': {
        'data': (df_02['packet_loss_percent'].fillna(0) / 100) * nt_pacotes,
        'params': (globals()['mle_loss_p_02'],)
    },
    'client12': {
        'data': (df_12['packet_loss_percent'].fillna(0) / 100) * nt_pacotes,
        'params': (globals()['mle_loss_p_12'],)
    }
}
plot_mle_comparative_diagnostics(loss_data_dict, 'Binomial', ('p',), f"Package Loss (Contagem)")

"""* Diagn√≥stico dos modelos para cada variavel analisando ambos clientes:

Para o grafico de throughput download, como observado anteriormente, os dados reais seguem um padr√£o de bimodalidade, o que nao √© capturado pelo modelo utilizando apens uma Gamma, contudo, como foi sugerido, o modelo de ambos os clientes parece se ajustar razoavelmente se nao considerarmos os picos existentes. J√° no grafico de throughput upload, o modelo Gamma se ajusta melhor, j√° que os dados dos clientes em vermelho (12) possuem dois picos proximos, o que √© bem caracterizado pelo modelo enquanto, mesmo que o cliente02 possua dois picos na distribuicao dos dados de upload, a maior parte dos dados √© espar√ßaem valores maiores de throughput o que √© bem capturado pelo modelo. Portanto, o ajuste do modelo parece razoavel, quando nao considerados os picos de throughput com valores muito baixos.

Para o grafico de RTT que utiliza uma variavel Normal, para download e upload os dados sao muito assimetricos, principalmente no caso do cliente 2, onde existe uma grande frequencia de valores com baixa latencia, mas alguns casos menos frequentes com valores um pouco mais altos. Dessa forma, o modelo nao parece se ajustar muito bem. Para o cliente 12, os dados sao um pouco mais simetricos, mesmo que seja bimodal, portando o modelo parece um pouco mais razoavel. Contudo, como notado anteriormente, seria melhor utilizar uma composicao de normais nesse caso.

J√° a variavel de package loss parece estar muito bem representada pela variavel binomial, principalmente quando o grafico com zoom (de 0 a 50 pacotes) √© analisado. O ajuste parece de acordo com a frequencia dos valores de perda de pacote, com maior quantidade ao inicio e melhores valores ao final dos graficos, principalmente para o cliente 12. O cliente 02 tambem tem o ajuste razoavel, principalmente quando comparados aos ajustes das outras variaveis.

**3.3 Infer√™ncia Bayesiana**

O objetivo deste item √© voc√™ usar os modelos que voc√™ escolheu no item acima e fazer a infer√™ncia Bayesiana. Para a infer√™ncia use uma prior conjugada para que a posterior perten√ßa √† mesma fam√≠lia. O objetivo √© facilitar os c√°lculos. Informa√ß√µes sobre priors conjugadas podem ser encontradas em Wikipedia e nos cap√≠tulos 2 e 3 do livro Bayesian
Data Analysis Third edition.

A infer√™ncia Bayesiana consiste em tr√™s etapas principais:
1. Definir um modelo de verossimilhan√ßa **(likelihood)** para os dados observados;
2. Especificar uma distribui√ß√£o a priori **(prior)** para os par√¢metros desconhecidos;
3. Calcular a distribui√ß√£o a posteriori **(posterior)** e, a partir dela, a distribui√ß√£o preditiva **(posterior predictive)** para novas observa√ß√µes.

**Modelagem e F√≥rmulas Utilizadas**

| Vari√°vel | Prior | Likelihood | Posterior | Posterior Predictive | $\mathbb{E}[Y_{novo} | \mathbf{r}]$ |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Throughput** | $\text{Gamma}(\alpha_0, \beta_0)$ | $\text{Gamma}(k, \beta)$ | $\text{Gamma}(\alpha_n, \beta_n)$ | $\text{Lomax} (k, \alpha_n, \beta_n)$ | $\frac{k \cdot \beta_n}{\alpha_n - 1} \quad (\text{para } \alpha_n > 1)$ |
| **RTT** | $\mathcal{N}(\mu_0, \tau^2_0)$ | $\mathcal{N}(\mu, \sigma^2)$ | $\mathcal{N}(\mu_n, \tau^2_n)$ | $\mathcal{N}(\mu_n, \sigma^2 + \tau_n^2)$ | $\mu_n = \tau_n^2 \left( \frac{\mu_0}{\tau_0^2} + \frac{N \bar{r}}{\sigma^2} \right)$ |
| **Package Loss** | $\text{Beta}(a_0, b_0)$ | $\text{Binomial}(n_t, p)$ | $\text{Beta}(a_n, b_n)$ | $\text{Beta-Binomial} (n_t, a_n, b_n)$ | $n_t \cdot \frac{a_n}{a_n + b_n}$ |

---

* Throughput download e upload:

  Prior $f(\theta)$ $d(\theta)$: $Gamma(\alpha_0, \beta_0)$

  Likelihood $p(x|Œ∏)$: $Gamma(k, \beta)$

  Posterior $f(\theta|x)$ $d(\theta)$ : $Gamma(\alpha_n, \beta_n)$

M√©dia dos clientes (implicita) √© dada por $\frac{k}{\beta}$.

Logo para uma prior informativa ($s=5$) mas flexivel, $\alpha_0 = 1+5 = 6$ e $\beta_0 = s \times \frac{m√©dia}{k}$. Aproximando o valor de $\beta$ para m√©dia de ambos clientes e upload e download, temos $\beta_0 = 10^9$ para uma estimativa de ordem de grandeza.
"""

s = 5
print(f"Throughput    client    k       beta        media       beta_0")
print(f" download       02    {k_mle_th_down_02:.4f}  {beta_mle_th_down_02:.4e}  {(k_mle_th_down_02/beta_mle_th_down_02):.4e}  {(s*(k_mle_th_down_02/beta_mle_th_down_02)/k_mle_th_down_02):.4e}")
print(f" download       12    {k_mle_th_down_12:.4f}  {beta_mle_th_down_12:.4e}  {(k_mle_th_down_12/beta_mle_th_down_12):.4e}  {(s*(k_mle_th_down_12/beta_mle_th_down_12)/k_mle_th_down_12):.4e}")
print(f"  upload        02    {mle_th_up_k_02:.4f}  {mle_th_up_beta_02:.4e}  {(mle_th_up_k_02/mle_th_up_beta_02):.4e}  {(s*(mle_th_up_k_02/mle_th_up_beta_02)/mle_th_up_k_02):.4e}")
print(f"  upload        12    {mle_th_up_k_12:.4f}  {mle_th_up_beta_12:.4e}  {(mle_th_up_k_12/mle_th_up_beta_12):.4e}  {(s*(mle_th_up_k_12/mle_th_up_beta_12)/mle_th_up_k_12):.4e} ")


media_beta_0 = (((s*(k_mle_th_down_02/beta_mle_th_down_02)/k_mle_th_down_02) + (s*(k_mle_th_down_12/beta_mle_th_down_12)/k_mle_th_down_12) + (s*(mle_th_up_k_02/mle_th_up_beta_02)/mle_th_up_k_02) +(s*(mle_th_up_k_12/mle_th_up_beta_12)/mle_th_up_k_12))/4)

print(f"media beta_0: {media_beta_0:.4e}")

"""* RTT download e upload:

  Prior $f(\theta)$ $d(\theta)$: $Normal(\mu_0, \tau^2_0)$

  Likelihood $p(x|Œ∏)$: $Normal(\mu, \sigma^2)$

  Posterior $f(\theta|x)$ $d(\theta)$ : $Normal(\mu_n, \tau^2_n)$
"""

print(f"    RTT      client     media     variancia")
print(f" download      02     {mle_rtt_down_media_02:.6f}    {mle_rtt_down_variancia_02:.6f} ")
print(f"  upload       02     {mle_rtt_up_media_02:.6f}    {mle_rtt_up_variancia_02:.6f} ")
print(f" download      12     {mle_rtt_down_media_12:.6f}    {mle_rtt_down_variancia_12:.6f} ")
print(f"  upload       12     {mle_rtt_up_media_12:.6f}    {mle_rtt_up_variancia_12:.6f} ")

media_geral = (mle_rtt_down_media_02 + mle_rtt_up_media_02 + mle_rtt_down_media_12 + mle_rtt_up_media_12)/4
print("media geral: ", media_geral)
variancia_geral = (mle_rtt_down_variancia_02 + mle_rtt_up_variancia_02 + mle_rtt_down_variancia_12 + mle_rtt_up_variancia_12)/4
print("variancia media: ", variancia_geral)

"""Para uma prior do tipo Normal, ser√° utilizada uma m√©dia $\mu = 0.05$ que se aproxima a m√©dia entre esses dois clientes nos dados observados, e uma variancia maior para que a prior nao sej√° t√£o forte e influencia muito nos dados, portanto $\tau^2_0 = 0.05$.

* Package loss:

  Prior $f(\theta)$ $d(\theta)$: $Beta(a_0, b_0)$

  Likelihood $p(x|Œ∏)$: $Binomial(n_t, p)$

  Posterior $f(\theta|x)$ $d(\theta)$ : $Beta(a_n, b_n)$

Defini√ß√£o de uma prior que n√£o seja t√£o forte, mas tamb√©m algo mais aproximado do que foi visto nos dados reais. Portanto, $a_0 = 1, b_0=50$, para que tenha uma m√©dia de $\frac{a}{a+b} = \frac{1}{51} = 0.0196$ e for√ßa $a+b=51$. Assim, a prior √© fraca mas enviesada para 0 j√° que os clientes analisados possuem baixa perda de pacotes.
"""

from scipy.stats import norm, gamma, beta, binom
from sklearn.model_selection import train_test_split

CLIENTE_ALVO = 'client12'
NT_PACOTES = 1000
TEST_SIZE = 0.3

# RTT (Normal)
PRIOR_RTT = {'mu0': 0.05, 'tau0_sq': 0.05}

# Throughput (Gamma)
PRIOR_THROUGHPUT = {'alpha0': 6, 'beta0': 1e9}

# Package Loss (Beta)
PRIOR_LOSS = {'a0': 1, 'b0': 50}

# INFERENCIA BAYESIANA
def calculate_bayesian_inference(df_cliente, nt_pacotes, prior_rtt, prior_throughput, prior_loss, test_size=0.3):
    """
    Executa a infer√™ncia Bayesiana e o calculo preditivo para todas as variaveis,
    utilizando as formulas de priors conjugadas fornecidas.
    """
    results = []

    # 1. PR√â-PROCESSAMENTO E DIVIS√ÉO TREINO/TESTE (70/30)
    data_splits = {}

    # RTT e Throughput
    for col in ['rtt_download_sec', 'rtt_upload_sec', 'download_throughput_bps', 'upload_throughput_bps']:
        data = df_cliente[col].dropna()
        if 'throughput' in col:
            data = data[data > 0] # Gamma exige que x > 0

        train, test = train_test_split(data, test_size=test_size, random_state=42)
        data_splits[col] = {'full': data, 'train': train, 'test': test}

    # Package Loss (Contagem)
    df_cliente['perdas_contagem'] = (df_cliente['packet_loss_percent'].fillna(0) / 100) * nt_pacotes
    data_loss = df_cliente['perdas_contagem']
    train_loss, test_loss = train_test_split(data_loss, test_size=test_size, random_state=42)
    data_splits['loss_contagem'] = {'full': data_loss, 'train': train_loss, 'test': test_loss}


# A. BINOMIAL (Package Loss - Infer√™ncia em p) - Prior Beta

    var_name = 'loss_contagem'
    data = data_splits[var_name]
    N_train = len(data['train'])

    # Priors
    a0, b0 = prior_loss['a0'], prior_loss['b0']
    r_sum = data['train'].sum()
    n_total_treino = N_train * nt_pacotes

    # Posterior (Beta)
    an = a0 + r_sum
    bn = b0 + n_total_treino - r_sum
    posterior_mean_p = an / (an + bn)
    mle_p = r_sum / n_total_treino

    # Preditiva (Beta-Binomial) - Usando a f√≥rmula fornecida
    # E[Y_novo | r] = n_t * a_n / (a_n + b_n)
    E_ppd = nt_pacotes * posterior_mean_p

    # Var[Y_novo | r] = n_t * E[p] * (1-E[p]) * (1 + (n_t - 1)/(a_n + b_n + 1))
    Var_ppd = nt_pacotes * posterior_mean_p * (1 - posterior_mean_p) * (1 + (nt_pacotes - 1) / (an + bn + 1))

    # Compara√ß√£o (Teste)
    test_mean = data['test'].mean()
    test_var = data['test'].var(ddof=1)

    results.append({
        'Vari√°vel': 'Package Loss (Contagem)',
        'Modelo': 'Binomial (Prior Beta)',
        'Parametro': 'p',
        'E[theta|r]': posterior_mean_p,
        'theta_MLE': mle_p,
        'E[Y_novo|r] (PPD)': E_ppd,
        'Var[Y_novo|r] (PPD)': Var_ppd,
        'Teste (M√©dia)': test_mean,
        'Teste (Vari√¢ncia)': test_var
    })

# B. NORMAL (RTT - Infer√™ncia em mu) - Prior Normal

    for var_name in ['rtt_download_sec', 'rtt_upload_sec']:
        data = data_splits[var_name]
        N_train = len(data['train'])

        # Par√¢metro Fixo (Vari√¢ncia MLE do conjunto COMPLETO)
        sigma2_mle = data['full'].var(ddof=0)

        # Priors
        mu0, tau0_sq = prior_rtt['mu0'], prior_rtt['tau0_sq']
        r_bar = data['train'].mean()
        mle_mu = r_bar

        # Posterior (Normal)
        # 1/tau_n^2 = 1/tau_0^2 + N/sigma^2
        tau_n_sq_inv = (1 / tau0_sq) + (N_train / sigma2_mle)
        tau_n_sq = 1 / tau_n_sq_inv
        # mu_n = tau_n^2 * (mu_0/tau_0^2 + N*r_bar/sigma^2)
        mu_n = tau_n_sq * ( (mu0 / tau0_sq) + (N_train * r_bar / sigma2_mle) )
        posterior_mean_mu = mu_n

        # Preditiva (Normal)
        E_ppd = mu_n
        Var_ppd = sigma2_mle + tau_n_sq

        # Compara√ß√£o (Teste)
        test_mean = data['test'].mean()
        test_var = data['test'].var(ddof=1)

        results.append({
            'Vari√°vel': var_name,
            'Modelo': 'Normal (Prior Normal)',
            'Parametro': 'mu',
            'E[theta|r]': posterior_mean_mu,
            'theta_MLE': mle_mu,
            'E[Y_novo|r] (PPD)': E_ppd,
            'Var[Y_novo|r] (PPD)': Var_ppd,
            'Teste (M√©dia)': test_mean,
            'Teste (Vari√¢ncia)': test_var
        })

# C. GAMMA (Throughput - Infer√™ncia em beta) - Prior Gamma

    for var_name in ['download_throughput_bps', 'upload_throughput_bps']:
        data = data_splits[var_name]
        N_train = len(data['train'])

        # Par√¢metro Fixo (Forma 'k' MLE do conjunto COMPLETO)
        # O fit retorna (k, loc, scale). k √© o par√¢metro de forma (shape).
        k_mle, _, _ = gamma.fit(data['full'], floc=0)

        # Priors
        alpha0, beta0 = prior_throughput['alpha0'], prior_throughput['beta0']
        y_sum = data['train'].sum()
        mle_beta = k_mle / data['train'].mean() # Beta = k/mean

        # Posterior (Gamma)
        alpha_n = alpha0 + N_train * k_mle
        beta_n = beta0 + y_sum
        posterior_mean_beta = alpha_n / beta_n

        # Preditiva (Lomax/Pareto II) - Usando as F√≥rmulas do seu PDF
        # O PDF usa: a_n = alpha_n (forma do posterior), b_n = beta_n (taxa do posterior) e k = k_mle

        # E[Y_novo | y] (existe se a_n > 1) -> a_n aqui √© alpha_n.
        E_ppd = np.nan
        if alpha_n > 1:
            # F√≥rmula Lomax do PDF: E[Y_novo|y] = (k * b_n) / (a_n - 1)
            E_ppd = (k_mle * beta_n) / (alpha_n - 1)

        # Var[Y_novo | y] (existe se a_n > 2) -> a_n aqui √© alpha_n.
        Var_ppd = np.nan
        if alpha_n > 2:
            # F√≥rmula Lomax do PDF: Var[Y_novo|y] = (k (k + a_n - 1) b_n^2) / ((a_n - 1)^2 (a_n - 2))
            Var_ppd = (k_mle * (k_mle + alpha_n - 1) * (beta_n**2)) / (((alpha_n - 1)**2) * (alpha_n - 2))

        # Compara√ß√£o (Teste)
        test_mean = data['test'].mean()
        test_var = data['test'].var(ddof=1)

        results.append({
            'Vari√°vel': var_name,
            'Modelo': 'Gamma (Prior Gamma)',
            'Parametro': 'beta',
            'E[theta|r]': posterior_mean_beta,
            'theta_MLE': mle_beta,
            'E[Y_novo|r] (PPD)': E_ppd,
            'Var[Y_novo|r] (PPD)': Var_ppd,
            'Teste (M√©dia)': test_mean,
            'Teste (Vari√¢ncia)': test_var
        })

    return pd.DataFrame(results)

df_raw = pd.read_csv('ndt_tests_corrigido.csv')
df_cliente = df_raw[df_raw['client'] == CLIENTE_ALVO].copy()

df_results = calculate_bayesian_inference(df_cliente, NT_PACOTES, PRIOR_RTT, PRIOR_THROUGHPUT, PRIOR_LOSS, TEST_SIZE)

print("### üìä Tabela de Compara√ß√£o de Estimativas e Previs√µes (Client12) ###")
print("Modelos ajustados com as suas Priors Semi-Informadas (70% Treino / 30% Teste)")
print("-" * 100)

df_results_formatted = df_results.copy()
for col in ['E[theta|r]', 'theta_MLE', 'E[Y_novo|r] (PPD)', 'Teste (M√©dia)']:
    df_results_formatted[col] = df_results_formatted[col].apply(lambda x: f"{x:.6f}" if not pd.isna(x) else 'N/A')
for col in ['Var[Y_novo|r] (PPD)', 'Teste (Vari√¢ncia)']:
    df_results_formatted[col] = df_results_formatted[col].apply(lambda x: f"{x:.8f}" if not pd.isna(x) else 'N/A')

print(df_results_formatted.to_markdown(index=False))

"""### üìù Conclus√µes da An√°lise Bayesiana (Interpreta√ß√£o Simples)

A an√°lise Bayesiana foi implementada usando as f√≥rmulas do fornecidas no pdf de projeto. Com base nos resultados sa tabela, temos que:

#### **1. O Efeito da Prior (Compara√ß√£o MLE vs Bayes)**

* **RTT (Download e Upload):**
    * As estimativas de Bayes ($\mathbb{E}[\mu|r]$) sao quase iguais ao MLE ($\hat{\mu}_{MLE}$). Portanto, a prior teve efeito praticamente nulo. Isso pode ter acontecido devido ao dataset conter muitos dados de modo que e a informa√ß√£o dos dados √© mais forte que a sugest√£o inicial da prior.

* **Perda de Pacotes ($p$):**
    * A estimativa de Bayes ($0.000781$) √© apenas um pouco maior que o MLE ($0.000778$), mas na mesma ordem de grandeza. Parece que a prior ($\text{Beta}(1, 50)$) influenciou minimamente o resultado do MLE (que √© mais baixo) e aumentou um pouco esse valor, a inten√ß√£o na estimativa de parametros era ter um valor mais proximo de um comportamento padrao de acordo com os dois clientes analisados, mas ambos ja possuiam baixa perda de pacotes como definido inicialmente, portanto j√° era esperado frequencia de valores baixos para perda de pacotes assim como na likelihood.

* **Throughput (Download e Upload):**
    * As estimativas do par√¢metro $\beta$ s√£o muito pequenas (pr√≥ximas de zero e arredondadas como $0$ na tabela), o que jpa √© esperado por conta da ordem de grandeza do parametro $\beta$. Assim, a prior nao deu grandes impactos no parametro principal da distribui√ß√£o Gamma.  

#### **2. Compara√ß√£o da Previs√£o com a Realidade (Dados de Teste)**

Analisamos se a previs√£o de novos dados (Posterior Predictive (PPD)) acerta a m√©dia e a vari√¢ncia de dados reais.

* **Acerto na M√©dia ($\mathbb{E}[Y_{novo}|r]$ vs Teste):**
    * A m√©dia PPD (um exemplo √© o download $4.73 \times 10^8$) √© muito pr√≥xima da m√©dia real dos dados de teste ($4.41 \times 10^8$). Portanto, o modelo acertou bem a m√©dia do que viria nos dados de teste.

* **Incerteza (Variancia PPD vs Teste):**
    * Throughput e Package loss: A vari√¢ncia PPD √© muito maior que a variancia real dos dados de teste (exemplo: package loss $0.78$ vs $0.24$).
    * RTT: A vari√¢ncia PPD ($0.0107$ e $0.0094$) ficou quase igual a variancia de teste ($0.0110$ e $0.0103$).
    * Conclus√£o Geral: A vari√¢ncia da previs√£o da Inferencia de Bayes √© mais alta j√° que ela soma a incerteza dos dados com a incerteza do modelo. Quando a incerteza do modelo √© zero (como no RTT), o resultado √© praticamente igual ao do teste, j√° quando h√° mais incerteza (Throughput/Package loss), o resultado √© mais conservador, admitindo uma variancia maior da posterior predictive (PPD) j√° que ainda existe a incerteza dos par√¢metros do modelo.
"""